{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b649211c-358c-48de-a2a7-973abf43cd96",
   "metadata": {},
   "source": [
    "# tf_to_dict.ipynb\n",
    "***example of interpreting saved tensorflow model as a python dictionary***\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bfd765-4558-4598-b57e-e587e781b0d4",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300e3304-aac4-4f85-88bb-e534c390a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "from tf_to_dict import tf_to_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8292b233-8230-43c0-a067-4b9dbddca33c",
   "metadata": {},
   "source": [
    "## tutorial\n",
    "here we'll load in an example tensorflow model, `pitchfork.h5`, from the `models` directory and use `tf_to_dict` to unpack the important information (like layer weights and biases, activation functions, branching architecture etc.) and save to a python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d8622-9f18-4cf5-a507-000ea34acaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'pitchfork'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe4884-9ce2-4468-a28a-a7b5feb06e56",
   "metadata": {},
   "source": [
    "this model was trained using custom objects, which tensorflow specifically needs to be redefined when we try to load in the saved model - so we'll have to define those here before we can even use the model (don't worry about these, you'll know if you need to define your custom objects properly because tensorflow will complain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84752165-536e-4a5a-9c0a-b4e971bcafea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InversePCA(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Inverse PCA layer for tensorflow neural network\n",
    "    \n",
    "    Usage:\n",
    "        - Define dictionary of custom objects containing Inverse PCA\n",
    "        - Use arguments of PCA mean and components from PCA of output parameters for inverse PCA (found in JSON dict)\n",
    "        \n",
    "    Example:\n",
    "\n",
    "    > f = open(\"pcann_info.json\")\n",
    "    >\n",
    "    > data = json.load(f)\n",
    "    >\n",
    "    > pca_comps = np.array(data[\"pca_comps\"])\n",
    "    > pca_mean = np.array(data[\"pca_mean\"])\n",
    "    > \n",
    "    > custom_objects = {\"InversePCA\": InversePCA(pca_comps, pca_mean)}\n",
    "    > pcann_model = tf.keras.models.load_model(\"pcann_name.h5\", custom_objects=custom_objects)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pca_comps, pca_mean, **kwargs):\n",
    "        super(InversePCA, self).__init__()\n",
    "        self.pca_comps = pca_comps\n",
    "        self.pca_mean = pca_mean\n",
    "        \n",
    "    def call(self, x):\n",
    "        y = tf.tensordot(x, np.float32(self.pca_comps),1) + np.float32(self.pca_mean)\n",
    "        return y\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'pca_comps': self.pca_comps,\n",
    "            'pca_mean': self.pca_mean\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class WMSE(tf.keras.losses.Loss):\n",
    "    \"\"\"\n",
    "    Weighted Mean Squared Error Loss Function for tensorflow neural network\n",
    "    \n",
    "    Usage:\n",
    "        - Define list of weights with len = labels\n",
    "        - Use weights as arguments - no need to square, this is handled in-function\n",
    "        - Typical usage - defining target precision on outputs for the network to achieve, weights parameters in loss calculation to force network to focus on parameters with unc >> weight.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, weights, name = \"WMSE\",**kwargs):\n",
    "        super(WMSE, self).__init__()\n",
    "        self.weights = np.float32(weights)\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        loss = ((y_true - y_pred)/(self.weights))**2\n",
    "        return tf.math.reduce_mean(loss)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'weights': self.weights\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def WMSE_metric(y_true, y_pred):\n",
    "    metric = ((y_true - y_pred)/(weights))**2\n",
    "    return tf.reduce_mean(metric)\n",
    "\n",
    "\n",
    "class emulator:\n",
    "    def __init__(self, emulator_name, file_path='pitchfork/'):\n",
    "        self.emulator_name = emulator_name\n",
    "        self.file_path = file_path + self.emulator_name\n",
    "        \n",
    "        with open(self.file_path+\".pkl\", 'rb') as fp:\n",
    "             self.emulator_dict = pickle.load(fp)\n",
    "\n",
    "        self.log_inputs_mean = np.array(self.emulator_dict[\"data_scaling\"][\"inp_mean\"][0])\n",
    "        \n",
    "        self.log_inputs_std = np.array(self.emulator_dict[\"data_scaling\"][\"inp_std\"][0])\n",
    "\n",
    "        self.log_outputs_mean = np.array(self.emulator_dict[\"data_scaling\"][\"classical_out_mean\"][0] + self.emulator_dict[\"data_scaling\"][\"astero_out_mean\"][0])\n",
    "        \n",
    "        self.log_outputs_std = np.array(self.emulator_dict[\"data_scaling\"][\"classical_out_std\"][0] + self.emulator_dict[\"data_scaling\"][\"astero_out_std\"][0])\n",
    "            \n",
    "        self.custom_objects = {\"InversePCA\": InversePCA(self.emulator_dict['custom_objects']['inverse_pca']['pca_comps'], self.emulator_dict['custom_objects']['inverse_pca']['pca_mean']),\"WMSE\": WMSE(self.emulator_dict['custom_objects']['WMSE']['weights'])}\n",
    "\n",
    "        self.model = tf.keras.models.load_model(self.file_path+\".h5\", custom_objects=self.custom_objects)\n",
    "\n",
    "        [print(str(key).replace(\"log_\",\"\") + \" range: \" + \"[min = \" + str(self.emulator_dict['parameter_ranges'][key][\"min\"]) + \", max = \" + str(self.emulator_dict['parameter_ranges'][key][\"max\"]) + \"]\") for key in self.emulator_dict['parameter_ranges'].keys()];\n",
    "\n",
    "    def predict(self, input_data, n_min=6, n_max=40, verbose=False):\n",
    "        \n",
    "        log_inputs = np.log10(input_data)\n",
    "        \n",
    "        standardised_log_inputs = (log_inputs - self.log_inputs_mean)/self.log_inputs_std\n",
    "\n",
    "        standardised_log_outputs = self.model(standardised_log_inputs)\n",
    "\n",
    "        standardised_log_outputs = np.concatenate((np.array(standardised_log_outputs[0]),np.array(standardised_log_outputs[1])), axis=1)\n",
    "\n",
    "        log_outputs = (standardised_log_outputs*self.log_outputs_std) + self.log_outputs_mean\n",
    "\n",
    "        outputs = 10**log_outputs\n",
    "\n",
    "        outputs[:,2] = log_outputs[:,2] ##we want star_feh in dex\n",
    "\n",
    "        teff = np.array(((outputs[:,1]*astropy.constants.L_sun) / (4*np.pi*constants.sigma*((outputs[:,0]*astropy.constants.R_sun)**2)))**0.25)\n",
    "        \n",
    "        outputs[:,0] = teff\n",
    "        \n",
    "        outputs = np.concatenate((np.array(outputs[:,:3]), np.array(outputs[:,n_min-3:n_max-2])), axis=1)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "with open(f'models/{model_name}_info.pkl', 'rb') as fp:\n",
    "    model_info = pickle.load(fp)\n",
    "\n",
    "custom_objects = {\n",
    "    \"InversePCA\": InversePCA(\n",
    "        model_info['custom_objects']['inverse_pca']['pca_comps'],\n",
    "        model_info['custom_objects']['inverse_pca']['pca_mean'],\n",
    "    ),\n",
    "    \"WMSE\": WMSE(\n",
    "        model_info['custom_objects']['WMSE']['weights'],\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6befa5f-ae8a-4d9b-8b05-c4f83c0afe5a",
   "metadata": {},
   "source": [
    "now we can load in the model using `tf.keras.models.load_model` and pass the custom objects to stop tensorflow from whining (again, you can remove the custom_objects keyword if you don't use any - you'll know if you need them by this point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff0f2b-9bd6-4441-be17-e2baf0c7eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = tf.keras.models.load_model(\n",
    "    f'models/{model_name}.h5', # <- change to keras.model if that's how you saved it!\n",
    "    custom_objects = custom_objects,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf118bc7-5f98-4eab-9c22-100438e88182",
   "metadata": {},
   "source": [
    "now we have our model loaded in, we can simply pass this to `tf_to_dict` and wave goodbye to tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b3468-2784-465a-942c-09202867ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtf_dict = tf_to_dict(tf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc48b6b8-3a79-4ec5-bbd2-76364140c928",
   "metadata": {},
   "source": [
    "this function returns a fully hashable python dictionary of weights, biases, activation functions, layer orders etc.\n",
    "\n",
    "it also prints out the interpretation of the network structure - you should definitely check this to make sure it matches what you're expecting!\n",
    "\n",
    "the dictionary is structured in a way that is easily interpreted by our compile functions (see `compile_from_dict.ipynb`), but should retain *some* degree of human readability.\n",
    "\n",
    "let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74318c-a57f-4534-bb6c-6e40cc437f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wtf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae696e28-9c97-4b5a-8026-608c0d43a962",
   "metadata": {},
   "source": [
    "once defined, this wtf_dict can be used directly by the compile_from_dict functions we'll look at in `compile_from_dict`, but it's probably best practice to save it as a json file and then we can load this in in a different environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df990f3-d9b6-402c-aee5-122d16255ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'models/{model_name}.json', 'w') as fp:\n",
    "    json.dump(wtf_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5bc93b-f2ae-4757-b872-d5e615190295",
   "metadata": {},
   "source": [
    "the idea here is that in our tensorflow training environment (where we have tensorflow installed to train models), you'd save a model using tensorflow as usual, and then immediately `tf_to_dict` the saved model and save as a json file to be used in a different environment where you no longer need tensorflow to be installed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
